"""
The configuration file would look like this (sans those // comments):

{
    "authority": "https://login.microsoftonline.com/Enter_the_Tenant_Name_Here",
    "client_id": "your_client_id",
    "scope": ["https://graph.microsoft.com/.default"],
        // For more information about scopes for an app, refer:
        // https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-client-creds-grant-flow#second-case-access-token-request-with-a-certificate"

    "secret": "The secret generated by AAD during your confidential app registration",
        // For information about generating client secret, refer:
        // https://github.com/AzureAD/microsoft-authentication-library-for-python/wiki/Client-Credentials#registering-client-secrets-using-the-application-registration-portal

    "endpoint": "https://graph.microsoft.com/v1.0/users"

}

You can then run this sample with a JSON configuration file:

    python sample.py parameters.json
"""

import os
import sys  # For simplicity, we'll read config file from 1st CLI param sys.argv[1]
import subprocess
import json
import csv
import logging
import datetime
import re
import pathlib
from shutil import copyfile
from dateutil import parser, tz

import requests
import msal

# Current script path
current_wdpath = os.path.dirname(__file__)

# Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(os.path.join(current_wdpath, "debug.log")),
        logging.StreamHandler()
    ]
)

client_id = os.getenv("daemon_client_id")
if not client_id:
    errmsg = "Define daemon_client_id environment variable"
    logging.error(errmsg)
    raise ValueError(errmsg)    
else:
    logging.info("client_id found -> '{0}'.".format(client_id))

client_secret = os.getenv("daemon_client_secret")
if not client_secret:
    errmsg = "Define daemon_client_secret environment variable"
    logging.error(errmsg)
    raise ValueError(errmsg)
else:
    logging.info("client_secret found.")

config = json.load(open(sys.argv[1]))

# Create a preferably long-lived app instance which maintains a token cache.
app = msal.ConfidentialClientApplication(
    client_id, authority=config["authority"],
    client_credential=client_secret,
    # token_cache=...  # Default cache is in memory only.
                       # You can learn how to use SerializableTokenCache from
                       # https://msal-python.rtfd.io/en/latest/#msal.SerializableTokenCache
    )

# The pattern to acquire a token looks like this.
result = None

# Firstly, looks up a token from cache
# Since we are looking for token for the current app, NOT for an end user,
# notice we give account parameter as None.
result = app.acquire_token_silent(config["scope"], account=None)

if not result:
    logging.info("No token exists in cache. Getting a new one from AzureAD.")
    result = app.acquire_token_for_client(scopes=config["scope"])

if "access_token" in result:

    yesterday = datetime.datetime.today() - datetime.timedelta(days=1)
    here_tz = tz.tzlocal()
    
    #request_filter = "filter=createdDateTime ge 2020-08-19T03:00:00Z and createdDateTime le 2020-08-20T03:00:00Z"
    request_filter = f"filter=createdDateTime ge {yesterday.strftime('%Y-%m-%d')}T03:00:00Z and createdDateTime le {datetime.datetime.today().strftime('%Y-%m-%d')}T03:00:00Z"
    request_order = "orderby=createdDateTime"
    endpoint_signIns = "{0}?&${1}&${2}".format(config["endpoint_signIns"], request_filter, request_order)

    logging.debug("Endpoint set as: '{0}'".format(endpoint_signIns))

    output_files_fname = "output-files"

    # Creates dir if does not exist.
    pathlib.Path(os.path.join(current_wdpath, output_files_fname)).mkdir(exist_ok=True)

    header_columns = [
        "Nome",
        "E-mailUniasselvi",
        "DataDeEntrada",
        "AplicativoMicrosoft",
        "AplicativoClienteUtilizado",
        "Navegador",
        "SistemaOperacional",
        "IPAddress",
        "Cidade",
        "Estado",
        "Pa√≠s"
    ]

    # HTML File
    html_template_path = os.path.join(current_wdpath, "template.html")
    html_file_path = os.path.join(current_wdpath, output_files_fname, "auditSignIns_{0}_generated_{1}.html".format(yesterday.strftime("%Y-%m-%d"), datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S")))

    copyfile(html_template_path, html_file_path)

    logging.info("Creating column headers in HTML file '{0}'.".format(html_file_path))

    with (open(html_file_path, "a", newline='', encoding='utf-8')) as html_file:
        html_file.write("<tr class=header>")    
        for header_name in header_columns:
            html_file.write(f"<td>{header_name}</td>")
        html_file.write("</tr>")
    

    # CSV File
    csv_file_path = os.path.join(current_wdpath, output_files_fname, "auditSignIns_{0}_generated_{1}.csv".format(yesterday.strftime("%Y-%m-%d"), datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S")))

    logging.info("Creating header row in CSV file '{0}'.".format(csv_file_path))

    with (open(csv_file_path, "w", newline='', encoding='utf-8')) as csv_file:
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(header_columns)

    def get_graph_data(endpoint):
        graph_data = requests.get(  # Use token to call downstream service
        endpoint,
        headers={'Authorization': 'Bearer ' + result['access_token']}, ).json()

        if "error" in graph_data:            
            logging.error("{0}: {1}".format(graph_data["error"]["code"], graph_data["error"]["message"]))
        else:        
            if not "@odata.nextLink" in graph_data:
                logging.info("Processing the last response page.")

        return graph_data
    
    def save_to_csv(graph_data):
        #print(json.dumps(graph_data, indent=2))
        with open('graph_data.json', 'w', encoding='utf-8') as f_json:
            json.dump(graph_data, f_json, ensure_ascii=False, indent=4)

        try:
            with (open(csv_file_path, "a", newline='', encoding='utf-8')) as csv_file:
                csv_writer = csv.writer(csv_file)
                for graph_data in graph_data["value"]:
                    csv_writer.writerow((
                        graph_data["userDisplayName"],
                        graph_data["userPrincipalName"],
                        graph_data["createdDateTime"],
                        graph_data["appDisplayName"],
                        graph_data["clientAppUsed"],
                        graph_data["deviceDetail"]["browser"],
                        graph_data["deviceDetail"]["operatingSystem"],
                        graph_data["ipAddress"],
                        graph_data["location"]["city"],
                        graph_data["location"]["state"],
                        graph_data["location"]["countryOrRegion"]
                    ))

            logging.info("CSV file appended.")
        except Exception as e:
            logging.error(f"Exception while generating CSV file: {str(e)}")            
        return

    def save_to_html(graph_data):
        try:
            with (open(html_file_path, "a", newline='', encoding='utf-8')) as html_file:
                for graph_data in graph_data["value"]:
                    converted_dt = parser.parse(graph_data["createdDateTime"])

                    html_file.write(
                        f"""
<tr>
<td>{graph_data['userDisplayName']}</td> 
<td>{graph_data['userPrincipalName']}</td> 
<td class=date>{converted_dt.astimezone(here_tz).strftime("%Y-%m-%d %H:%M:%S,%f")}</td>
<td>{graph_data['appDisplayName']}</td> 
<td>{graph_data['clientAppUsed']}</td> 
<td>{graph_data['deviceDetail']['browser']}</td> 
<td>{graph_data['deviceDetail']['operatingSystem']}</td> 
<td>&nbsp;{graph_data['ipAddress']}</td> 
<td>{graph_data['location']['city']}</td> 
<td>{graph_data['location']['state']}</td> 
<td>{graph_data['location']['countryOrRegion']}</td> 
</tr>
""")

            logging.info("HTML file appended.")                    
        except Exception as e:
            logging.error(f"Exception while generating HTML file: {str(e)}")
        return

    logging.info("Sending request do endpoint.")

    try:
        graph_data = get_graph_data(endpoint_signIns)
        save_to_html(graph_data)
        save_to_csv(graph_data)

        while "@odata.nextLink" in graph_data:        
            graph_data = get_graph_data(graph_data["@odata.nextLink"])
            save_to_html(graph_data)
            save_to_csv(graph_data)
    
    except Exception as e:
        logging.error(f"Exception while getting graph data: {str(e)}")

    # Close html file.
    with (open(html_file_path, "a", newline='', encoding='utf-8')) as html_file:
        html_file.write("</table></body></html>")

    logging.info("Finished getting result pages, everything exported to CSV file '{0}'.".format(csv_file_path))

    # Send to PowerShell to convert to Excel and send by e-mail.
    ps_script_path = os.path.join(current_wdpath, "ConvertTo-ExcelCustomReportHTML.ps1")
    #ps_html_path = os.path.join(current_wdpath, "teste.html")
    ps_xlsx_path = os.path.join(current_wdpath, output_files_fname, f"AuditoriaEntrada_{yesterday.strftime('%d-%m-%Y')}_Completo.xlsx")

    ps_arg = f"{ps_script_path} -HtmlPath {html_file_path} -XlsxPath {ps_xlsx_path}"

    try:
        subprocess.Popen([
            "powershell.exe",
            f"{ps_arg}"
            ])
        
        logging.info(f"Calling PowerShell to finish the job: {ps_arg}")

    except Exception as e:
        logging.error(f"Exception while calling PowerShell: {str(e)}")

        
else:
    #logging.error("{0}: {1} (correlation_id: {3})".format(result.get("error"), result.get("error_description"), result.get("correlation_id")))
    logging.error(f"{result.get('error')}: {result.get('error_description')} (correlation_id: {result.get('correlation_id')})")
    print(result.get("error"))
    print(result.get("error_description"))
    print(result.get("correlation_id"))  # You may need this when reporting a bug

